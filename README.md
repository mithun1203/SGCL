# Semantic Inconsistency Detector (SID)

## Part of the Symbolic-Gated Continual Learning (SG-CL) Framework

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A neuro-symbolic module for detecting semantic conflicts in knowledge statements. SID is the core conflict detection component of the SG-CL framework, designed to prevent semantic inconsistencies in Large Language Model fine-tuning.

---

## üéØ What Problem Does SID Solve?

During sequential fine-tuning of LLMs, models can learn contradictory information:

```
Task 1: "All birds can fly"
Task 2: "Penguins are birds"  
Result: Model incorrectly infers "Penguins can fly" ‚ùå
```

**SID detects such semantic conflicts BEFORE training by:**
1. Extracting semantic triples from input text
2. Querying external knowledge (ConceptNet) for related facts
3. Applying conflict detection rules
4. Performing inheritance-based reasoning

---

## ‚ú® Key Features

- ‚úÖ **Multi-backend NLP**: Supports spaCy, Stanza, and rule-based extraction
- ‚úÖ **ConceptNet Integration**: Queries commonsense knowledge for conflict detection
- ‚úÖ **Offline Mode**: Works without internet using pre-loaded knowledge base
- ‚úÖ **Caching**: Efficient caching of knowledge base queries
- ‚úÖ **Inheritance Reasoning**: Detects conflicts through type hierarchies
- ‚úÖ **Detailed Evidence**: Provides reasoning chains for detected conflicts
- ‚úÖ **Batch Processing**: Efficiently process multiple statements
- ‚úÖ **Easily Integrable**: Clean API for SG-CL training loop integration

---

## üèóÔ∏è Architecture

```
SID Module Architecture
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Input Text                                ‚îÇ
‚îÇ              "Penguins can fly"                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Entity Extractor                            ‚îÇ
‚îÇ    (spaCy / Stanza / Rule-based)                            ‚îÇ
‚îÇ    Entities: [penguin, fly]                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Relation Mapper                             ‚îÇ
‚îÇ    Pattern matching + Dependency parsing                     ‚îÇ
‚îÇ    Triple: (penguin, CapableOf, fly)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                ConceptNet Client                             ‚îÇ
‚îÇ    KB Facts: (penguin, NotCapableOf, fly)                   ‚îÇ
‚îÇ              (penguin, IsA, bird)                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Conflict Engine                             ‚îÇ
‚îÇ    Result: CONFLICT DETECTED                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Project Structure:**
```
SGCL new/
‚îú‚îÄ‚îÄ sid/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Module exports
‚îÇ   ‚îú‚îÄ‚îÄ models.py                # Data models (Triple, ConflictResult, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ detector.py              # Main SemanticInconsistencyDetector
‚îÇ   ‚îú‚îÄ‚îÄ conceptnet_client.py     # ConceptNet API client
‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor.py      # NLP entity extraction
‚îÇ   ‚îú‚îÄ‚îÄ relation_mapper.py       # Text to relation mapping
‚îÇ   ‚îú‚îÄ‚îÄ conflict_engine.py       # Conflict detection logic
‚îÇ   ‚îú‚îÄ‚îÄ hybrid_kb.py             # Hybrid knowledge base (JSON + embeddings)
‚îÇ   ‚îú‚îÄ‚îÄ numberbatch_kb.py        # ConceptNet Numberbatch embeddings
‚îÇ   ‚îú‚îÄ‚îÄ download_numberbatch.py  # Download script for mini embeddings
‚îÇ   ‚îú‚îÄ‚îÄ knowledge_base.json      # Offline knowledge (54+ concepts)
‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ       ‚îî‚îÄ‚îÄ mini.h5              # Numberbatch embeddings (optional, ~150MB)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ test_sid.py              # Comprehensive test suite (100+ tests)
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ usage_examples.py        # Usage demonstrations
‚îú‚îÄ‚îÄ demo.py                      # Quick demo script
‚îú‚îÄ‚îÄ test_hybrid_kb.py            # Hybrid KB test suite
‚îú‚îÄ‚îÄ requirements.txt             # Dependencies
‚îî‚îÄ‚îÄ README.md                    # This file
```

---

## üîÑ SG-CL Pipeline Integration

SID is designed for seamless integration into the full SG-CL pipeline:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     SG-CL PIPELINE FLOW                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

  SeCA Dataset          SID Analysis         Gating Decision
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ Task 1  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ  Conflict ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Normal   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ LLM Train
  ‚îÇ Task 2  ‚îÇ          ‚îÇ  Check    ‚îÇ         ‚îÇ   or      ‚îÇ
  ‚îÇ Task 3  ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ  Gated?   ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ                     ‚îÇ
                             ‚ñº                     ‚ñº
                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ Guard-Rail‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  Gated    ‚îÇ
                      ‚îÇ Generator ‚îÇ         ‚îÇ Training  ‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                   ‚îÇ
                                                   ‚ñº
                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                            ‚îÇ    SCP    ‚îÇ
                                            ‚îÇ Evaluation‚îÇ
                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pipeline Components

| Component | Status | Description |
|-----------|--------|-------------|
| `SeCADataset` | ‚úÖ Ready | Sequential task input format |
| `SIDPipelineAdapter` | ‚úÖ Ready | SID integration for pipeline |
| `GatingController` | ‚úÖ Ready | Training path decision |
| `BasicGuardRailGenerator` | ‚úÖ Ready | Guard-rail generation |
| `SGCLTrainerInterface` | üìã Interface | LLM training (Phase 2) |
| `SCPEvaluator` | üìã Interface | Evaluation (Phase 2) |

### Pipeline Usage

```python
from sid.pipeline import create_pipeline

# Create pipeline
pipeline = create_pipeline(offline_only=True)

# Add sequential tasks (SeCA format)
pipeline.add_task("Birds can fly", "Sparrows are birds")
pipeline.add_task("Penguins are birds", "Penguins can fly")  # Conflict!

# Add evaluation probes
pipeline.add_scp_probe(
    premise="Penguins are birds",
    hypothesis="Penguins can fly",
    expected=False
)

# Run simulation (no LLM needed)
results = pipeline.run_simulation()

# Output:
# Conflicts detected: 1
# Guard-rails generated: ["Penguin is a type of bird.", 
#                         "While birds can fly, penguins are an exception..."]
```

### Pipeline Demo Output

```
============================================================
SG-CL PIPELINE SIMULATION
============================================================

--- TASK 0: General Bird Knowledge ---
  [OK] Batch 0: Normal training

--- TASK 1: Penguin Knowledge ---
  [CONFLICT] "Penguins can fly."
             -> direct_contradiction
  [GUARD-RAILS] ['Penguin is a type of bird.', 
                 'While birds generally can fly, penguins are an exception...']

============================================================
PIPELINE SUMMARY
============================================================
Tasks processed: 3
Conflicts detected: 1
Guard-rails generated: 3
```

---

## üöÄ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/your-username/sgcl.git
cd sgcl

# Install dependencies
pip install requests

# Optional: Install NLP backends for better extraction
pip install spacy
python -m spacy download en_core_web_sm

# Optional: Install Numberbatch embeddings support
pip install h5py numpy
```

### Knowledge Sources

SID supports multiple knowledge sources for flexibility:

| Source | Size | Description | Use Case |
|--------|------|-------------|----------|
| **JSON KB** | ~50 KB | Curated facts for 54+ concepts | Default, always available |
| **ConceptNet API** | Online | Live API queries | Full coverage (when available) |
| **Numberbatch Mini** | ~150 MB | Semantic embeddings | Offline inference for unknown concepts |

#### "ConceptNet Mini" Mode (Recommended for Offline Use)

For reliable offline operation without the 9GB full ConceptNet database:

```bash
# Download Numberbatch Mini embeddings (~150MB)
python -m sid.download_numberbatch --type mini
```

This provides:
- ‚úÖ Semantic similarity for ~500K concepts
- ‚úÖ Works completely offline
- ‚úÖ Fast inference (<10ms per query)
- ‚úÖ Only ~150MB storage (vs 9GB for full database)

### Basic Usage

```python
from sid import SemanticInconsistencyDetector, create_detector

# Create detector (uses offline mode by default)
detector = create_detector()

# Check for conflicts
result = detector.detect_conflict("Penguins can fly")

print(f"Has conflict: {result.has_conflict}")  # True
print(f"Conflicts: {result.conflict_count}")   # 1

# Get detailed explanation
if result.has_conflict:
    for conflict in result.conflicts:
        print(conflict.explain())
```

### Using the Hybrid Knowledge Base Directly

```python
from sid.hybrid_kb import HybridKnowledgeBase

# Create hybrid KB (JSON + Numberbatch)
kb = HybridKnowledgeBase()

# Check capability
can_fly, confidence, source = kb.check_capability("penguin", "fly")
print(f"Penguin can fly: {can_fly}")  # False
print(f"Confidence: {confidence}")    # 1.0
print(f"Source: {source}")            # json_kb

# Check relationships
is_bird, conf, src = kb.check_relationship("penguin", "is_a", "bird")
print(f"Penguin is a bird: {is_bird}")  # True
```

### Batch Processing

```python
texts = [
    "Birds can fly",
    "Penguins are birds", 
    "Penguins can fly"  # This conflicts!
]

batch_result = detector.detect_conflicts_batch(texts)
print(batch_result.summary())
```

### SG-CL Training Loop Integration

```python
from sid import create_detector

detector = create_detector()

def sgcl_training_loop(model, tasks):
    for task in tasks:
        for batch in task:
            for sample in batch:
                # SID conflict detection
                result = detector.detect_conflict(sample.text)
                
                if result.has_conflict:
                    # Apply gated training + guardrails
                    sample.requires_gating = True
                    gated_train(model, batch, result.conflicts)
                else:
                    # Normal fine-tuning
                    normal_train(model, batch)
```

---

## üìö API Reference

### SemanticInconsistencyDetector

| Method | Description |
|--------|-------------|
| `detect_conflict(text)` | Detect conflicts in text, returns `ConflictResult` |
| `detect_conflicts_batch(texts)` | Process multiple texts |
| `is_conflicting(text)` | Quick boolean check |
| `get_conflicts(text)` | Get list of conflicts |
| `check_triple(triple)` | Check a pre-extracted triple |
| `extract_triples(text)` | Extract triples without conflict checking |
| `query_knowledge(concept)` | Query knowledge base |
| `explain(text)` | Get detailed analysis |

### ConflictResult

| Property | Description |
|----------|-------------|
| `has_conflict` | Boolean - whether conflicts detected |
| `conflict_count` | Number of conflicts |
| `conflicts` | List of ConflictEvidence |
| `extracted_triples` | Triples from input |
| `processing_time` | Time in seconds |

---

## üß™ Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=sid --cov-report=html

# Run specific tests
pytest tests/test_sid.py::TestSemanticInconsistencyDetector -v
```

### Test Coverage

- `TestTriple`: Triple data structure tests
- `TestConceptNetClient`: Knowledge base client tests
- `TestEntityExtractor`: NLP extraction tests
- `TestRelationMapper`: Relation mapping tests
- `TestConflictEngine`: Conflict detection tests
- `TestSemanticInconsistencyDetector`: Main detector tests
- `TestIntegration`: End-to-end tests
- `TestEdgeCases`: Edge case handling

---

## üìä Performance

- **Detection time**: <100ms per sentence (with caching)
- **Cache hit rate**: >90% for common concepts
- **Offline KB**: 54+ pre-loaded concepts for instant lookup
- **Numberbatch**: ~500K concepts via semantic similarity
- **Batch processing**: Efficient parallel knowledge retrieval
- **Storage**: Only ~150MB for full offline operation

### Test Results

```
============================================================
HYBRID KNOWLEDGE BASE TEST SUITE
============================================================

Total Passed: 39
Total Failed: 0
Success Rate: 100.0%

==> ALL TESTS PASSED!
```

---

## üîÆ Phase 2 Roadmap

- [ ] Guard-rail Generator implementation
- [ ] SG-CL Trainer with gated updates
- [ ] SeCA dataset creation
- [ ] SCP evaluation metrics
- [ ] Full LLM training experiments

---

## üìù Citation

```bibtex
@misc{sgcl2024,
  title={Symbolic-Gated Continual Learning: A Neuro-Symbolic Framework 
         for Mitigating Semantic Inconsistency in Generative Models},
  author={Mithun Naik},
  year={2024},
  note={Capstone Project}
}
```

---

## üìÑ License

MIT License

---

**Author**: Mithun Naik  
**Project**: SGCL Capstone  
**Version**: 1.0.0
